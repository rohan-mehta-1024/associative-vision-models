{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdeadd-2c4d-4111-9859-0ee348eaea45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import jax\n",
    "import torch\n",
    "import optax\n",
    "import wandb \n",
    "import shutil\n",
    "import functools\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import jax.numpy as jnp\n",
    "import plotly.express as px\n",
    "from functools import partial\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "from pydash import flatten_deep as flatten, unzip\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74bfd4-fd92-4c71-8d08-c2da637e4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset of unmasked faces\n",
    "\n",
    "class UnmaskedFaces():\n",
    "    def __init__(self, mode, transform=[lambda x: x], splits=[0.8, 0.1]):\n",
    "        super().__init__()\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.splits = splits\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            Image.open, \n",
    "            lambda x: x.resize((150,150)), \n",
    "            transforms.ToTensor(),\n",
    "            *transform\n",
    "        ])\n",
    "        \n",
    "        self.label_mapping = {i[1] : i[0] for i in enumerate(os.listdir(\"LFW\"))}\n",
    "\n",
    "    def get_name(self, path):\n",
    "        no_digits = lambda x: not any([i.isdigit() for i in x])\n",
    "        file = path.split(\"/\")[2].split(\"_\")\n",
    "        return \"_\".join(list(filter(no_digits, file)))\n",
    "    \n",
    "    def read_LFW(self):\n",
    "        raw_lfw = [glob.glob(f\"LFW/{person}/*.jpg\") for person in os.listdir(\"LFW\")]\n",
    "        return raw_lfw\n",
    "    \n",
    "    def preprocess(self, sample_list): \n",
    "        images, labels = sample_list, [self.get_name(i) for i in sample_list]\n",
    "        images = torch.stack([self.transform(i) for i in images]).float()\n",
    "        labels = torch.tensor([self.label_mapping[i] for i in labels])\n",
    "        return images, F.one_hot(labels, len(os.listdir(\"LFW\")))\n",
    "    \n",
    "    def generate_dataloader(self):\n",
    "        data = flatten(self.read_LFW())\n",
    "        dataset = TensorDataset(*self.preprocess(data))\n",
    "        \n",
    "        indices = np.array(list(range(len(data))))\n",
    "        np.random.permutation(indices)\n",
    "        data_splits = [int(len(indices) * i) for i in self.splits]\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            datapoints = indices[:data_splits[0]]\n",
    "        elif self.mode == \"val\":\n",
    "            datapoints = indices[data_splits[0]:data_splits[0]+data_splits[1]]\n",
    "        else: datapoints = indices[data_splits[0]+data_splits[1]:]\n",
    "        \n",
    "        return lambda b: DataLoader(\n",
    "            dataset, \n",
    "            batch_size=b, \n",
    "            sampler=SubsetRandomSampler(np.array(datapoints))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d3a4f-e290-4885-a175-52b67bdf6e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define pseudo-masking functions\n",
    "\n",
    "def mask_lower_half_of_image(img, value, amount=0.5):\n",
    "    nth_pixel = img[0].shape[0]\n",
    "    half = int(nth_pixel * (1 - amount))\n",
    "    minus_half = nth_pixel - half\n",
    "    \n",
    "    if value == \"random_one\":\n",
    "        random = torch.rand(3,1)\n",
    "        random=random.unsqueeze(1).repeat(1, half, nth_pixel)\n",
    "        img[:, minus_half:, :]=random\n",
    "        return img\n",
    "    elif value == \"random_many\":\n",
    "        random = torch.rand((3, half, nth_pixel))\n",
    "        img[:, minus_half:, :]=random\n",
    "        return img\n",
    "    else:\n",
    "        ones = torch.ones(3, half, nth_pixel)\n",
    "        zeros = torch.zeros(3, minus_half, nth_pixel)\n",
    "        mask = torch.concat((ones, zeros), 1) == 0 \n",
    "        mask = torch.reshape(mask, (3, nth_pixel, nth_pixel))\n",
    "        return img.masked_fill(mask, 0)\n",
    "\n",
    "def mask_with_prob_color(img, prob, value):\n",
    "    mask = (torch.rand(size=(50,50)) < prob).int()\n",
    "    l, counter = [], 0\n",
    "    rnd_block = torch.rand(3,1).unsqueeze(1).repeat(1,2,2)\n",
    "    \n",
    "    for i in mask:\n",
    "        a = []\n",
    "        for b in range(len(i)):\n",
    "            if i[b] != torch.tensor(0):\n",
    "                if value == \"random_one\":\n",
    "                    a.append(rnd_block)\n",
    "                else: a.append(torch.rand(3,2,2))\n",
    "            else: \n",
    "                x_dim = counter*2\n",
    "                y_dim = int(b)*2\n",
    "                a.append(img[:, x_dim:x_dim+2, y_dim:y_dim+2])\n",
    "        l.append(torch.concat(a, dim=2))\n",
    "        mask = torch.concat(l, dim=1)\n",
    "        counter+=1\n",
    "    return mask\n",
    "    \n",
    "def mask_with_prob(img, prob):\n",
    "    mask = (torch.rand(size=(50,50)) < prob).int()\n",
    "    l = []\n",
    "    \n",
    "    for i in mask:\n",
    "        a = []\n",
    "        for b in i:\n",
    "            a.append(b.repeat(2,2))\n",
    "            \n",
    "        l.append(torch.concat(a, dim=1))\n",
    "        mask = torch.concat(l, dim=0)\n",
    "    \n",
    "    mask = torch.stack((mask,mask,mask), dim=0)\n",
    "    return img.masked_fill(mask, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362685a-59c5-469a-8492-f46075faf378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize datasets\n",
    "\n",
    "unmasked_train_lfw = UnmaskedFaces(\"train\", transform=[lambda x: mask_lower_half_of_image(x, \"random_many\")]).generate_dataloader()\n",
    "#unmasked_val_lfw = UnmaskedFaces(\"val\").generate_dataloader()\n",
    "#unmasked_test_lfw = UnmaskedFaces(\"test\").generate_dataloader()\n",
    "\n",
    "# masked_25_percent_black_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob(x, 0.25)]).generate_dataloader(indices)\n",
    "# masked_50_percent_black_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob(x, 0.50)]).generate_dataloader(indices)\n",
    "# masked_75_percent_black_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob(x, 0.75)]).generate_dataloader(indices)\n",
    "# masked_quarter_black_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, 0, 0.25)]).generate_dataloader(indices)\n",
    "# masked_half_black_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, 0, 0.5)]).generate_dataloader(indices)\n",
    "# masked_three_quarters_black_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, 0, 0.75)]).generate_dataloader(indices)\n",
    "\n",
    "# masked_25_percent_random_one_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob_color(x, 0.25, \"random_one\")]).generate_dataloader(indices)\n",
    "# masked_50_percent_random_one_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob_color(x, 0.50, \"random_one\")]).generate_dataloader(indices)\n",
    "# masked_75_percent_random_one_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob_color(x, 0.75, \"random_one\")]).generate_dataloader(indices)\n",
    "# masked_quarter_random_one_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, \"random_one\", 0.75)]).generate_dataloader(indices)\n",
    "# masked_half_random_one_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, \"random_one\", 0.5)]).generate_dataloader(indices)\n",
    "# masked_three_quarters_random_one_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, \"random_one\", 0.25)]).generate_dataloader(indices)\n",
    "\n",
    "# masked_25_percent_random_many_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob_color(x, 0.25, \"random_many\")]).generate_dataloader(indices)\n",
    "# masked_50_percent_random_many_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob_color(x, 0.50, \"random_many\")]).generate_dataloader(indices)\n",
    "# masked_75_percent_random_many_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_with_prob_color(x, 0.75, \"random_many\")]).generate_dataloader(indices)\n",
    "# masked_quarter_random_many_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, \"random_many\", 0.75)]).generate_dataloader(indices)\n",
    "# masked_half_random_many_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, \"random_many\", 0.5)]).generate_dataloader(indices)\n",
    "# masked_three_quarters_random_many_lfw = UnmaskedFaces(\"test\", transform=[lambda x: mask_lower_half_of_image(x, \"random_many\", 0.25)]).generate_dataloader(indices)\n",
    "\n",
    "#truly_masked = UnmaskedFaces(\"train\", transform=[lambda x: x]).generate_dataloader_2(\n",
    "#    jax.random.randint(key, (1, 100), 10, 100)[0]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3bb21-b19b-4ce8-8d41-299f82197d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize datasets\n",
    "\n",
    "dataloaders = [\n",
    "    unmasked_train_lfw,\n",
    "    #unmasked_val_lfw, \n",
    "    #unmasked_test_lfw, \n",
    "    # masked_25_percent_black_lfw, \n",
    "    # masked_50_percent_black_lfw, \n",
    "    # masked_75_percent_black_lfw, \n",
    "    # masked_quarter_black_lfw, \n",
    "    # masked_half_black_lfw,\n",
    "    # masked_three_quarters_black_lfw, \n",
    "    # masked_25_percent_random_one_lfw, \n",
    "    # masked_50_percent_random_one_lfw, \n",
    "    # masked_75_percent_random_one_lfw, \n",
    "    # masked_quarter_random_one_lfw, \n",
    "    # masked_half_random_one_lfw,\n",
    "    # masked_three_quarters_random_one_lfw,\n",
    "    # masked_25_percent_random_many_lfw, \n",
    "    # masked_50_percent_random_many_lfw, \n",
    "    # masked_75_percent_random_many_lfw, \n",
    "    # masked_quarter_random_many_lfw, \n",
    "    # masked_half_random_many_lfw, \n",
    "    # masked_three_quarters_random_many_lfw,\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(100,100))\n",
    "def get_first_img(dataloader):\n",
    "    for img, _ in dataloader(1):\n",
    "        print(img.shape)\n",
    "        return img[0]\n",
    "\n",
    "def plot_img(img, num):\n",
    "    sub = fig.add_subplot(5, 5, num + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "for i in range(len(dataloaders)):\n",
    "    img = get_first_img(dataloaders[i])\n",
    "    img = torch.permute(img, (1, 2, 0))\n",
    "    plot_img(img, i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4a7d6-0b80-4410-b9c7-7eb5ed05cad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define architecture of encoder\n",
    "\n",
    "class Encoder(hk.nets.ResNet):\n",
    "    def __init__(self, projection):\n",
    "        configs = hk.nets.ResNet.CONFIGS[50].copy()\n",
    "        self.projection = projection \n",
    "        super().__init__(num_classes=projection if projection else 1, **configs)\n",
    "        \n",
    "        \n",
    "    def __call__(self, inputs, is_training, memory=None, test_local_stats=False):\n",
    "            out = inputs\n",
    "            out = self.initial_conv(out)\n",
    "            if not self.resnet_v2:\n",
    "              out = self.initial_batchnorm(out, is_training, test_local_stats)\n",
    "              out = jax.nn.relu(out)\n",
    "\n",
    "            out = hk.max_pool(out,\n",
    "                              window_shape=(1, 3, 3, 1),\n",
    "                              strides=(1, 2, 2, 1),\n",
    "                              padding=\"SAME\")\n",
    "\n",
    "            for block_group in self.block_groups:\n",
    "              out = block_group(out, is_training, test_local_stats)\n",
    "\n",
    "            if self.resnet_v2:\n",
    "              out = self.final_batchnorm(out, is_training, test_local_stats)\n",
    "              out = jax.nn.relu(out)\n",
    "            out = jnp.mean(out, axis=(1, 2))\n",
    "            \n",
    "            if self.projection:\n",
    "                return self.logits(out)\n",
    "            else: return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f9bd6-ca82-401a-bc89-65a37e147d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define (and visualize) architecture of Hopfield network \n",
    "\n",
    "class Hopfield(hk.Module):\n",
    "    def __init__(self, beta, sim, sep, norm=False, self_retrieval=True):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.sim = sim\n",
    "        self.sep = sep\n",
    "        self.norm = norm\n",
    "        self.self_retrieval = self_retrieval\n",
    "        self.encoder = Encoder(projection=None)\n",
    "        self.projection = hk.Linear(output_size=5)\n",
    "    \n",
    "    def hopfield(self, memory, query):\n",
    "        @functools.partial(jax.vmap, in_axes=(None, 0))\n",
    "        def sim_sep_project(memory, query):\n",
    "            memory, query = memory, jax.lax.expand_dims(query, [-1])\n",
    "            sim_score = self.beta * self.sim(memory, query)\n",
    "            sim_score = sim_score / jnp.sum(sim_score) if self.norm else sim_score\n",
    "            sep_score = self.sep(sim_score, axis=0)\n",
    "            sep_score = sep_score / jnp.sum(sep_score) if self.norm else sep_score\n",
    "            out = jnp.dot(memory.T, sep_score)\n",
    "            return jax.lax.squeeze(out, [1]), jax.lax.squeeze(sep_score, [1])\n",
    "        return sim_sep_project(memory, query)\n",
    "    \n",
    "    def apply_self_retrieval(self, memory, query):\n",
    "        return self.hopfield(memory, query)\n",
    "        \n",
    "    def apply_no_self_retrieval(self, x):\n",
    "        one, two = jnp.split(x, 2)\n",
    "        x_one, _ = self.hopfield(two, one)\n",
    "        x_two, _ = self.hopfield(one, two)\n",
    "        x = jnp.concatenate((x_one, x_two), axis=0)\n",
    "        return x, None\n",
    "    \n",
    "    @staticmethod\n",
    "    def eucdliean_distance(K, q):\n",
    "        return -jnp.sum(jnp.square(q - K), axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def manhattan_distance(K, q):\n",
    "        return -jnp.sum(jnp.abs(q - K), axis=1)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_similarity(K, q):\n",
    "        return (K @ q) / (torch.norm(K) * torch.norm(q))\n",
    "    \n",
    "    @staticmethod\n",
    "    def dot_product(K, q):\n",
    "        return K @ q\n",
    "\n",
    "    def __call__(self, x, memory, is_training):\n",
    "        \n",
    "        print(\"fulk1\", str(self.self_retrieval))\n",
    "        x = self.encoder(x, is_training)\n",
    "        if not self.self_retrieval:\n",
    "            print(\"fulk222\")\n",
    "            x = self.apply_no_self_retrieval(x)\n",
    "        elif memory != None:\n",
    "            print(\"fulk\")\n",
    "            x = self.apply_self_retrieval(self.encoder(memory, is_training), x)\n",
    "        else: \n",
    "            x = self.apply_self_retrieval(x, x) \n",
    "        logits = self.projection(x[0])\n",
    "        return logits, x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b400f-7ebd-41e9-ba99-77e81f101c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define uility functions \n",
    "\n",
    "def get_acc(logits, labels):\n",
    "    argmax = jnp.argmax(logits, axis=1)\n",
    "    encoded = jax.nn.one_hot(argmax, num_classes=labels.shape[1])\n",
    "    return jnp.mean(jnp.all(labels == encoded, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b2ac1-f280-4782-8096-822a9040e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loaders,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    sim,\n",
    "    method_num,\n",
    "    task_num,\n",
    "    beta,\n",
    "    encoder_only,\n",
    "    pretrained_encoder,\n",
    "    save_as,\n",
    "    sweeps):\n",
    "    sim=eval(sim)\n",
    "    if not sweeps:\n",
    "        wandb.init(project=\"final_hopfield_masked\")\n",
    "    if encoder_only:\n",
    "        model = lambda x, is_training: Encoder(5)(x, is_training)\n",
    "    elif pretrained_encoder:\n",
    "        pass\n",
    "    else: \n",
    "        self_retrieval=True if method_num == 1 else False\n",
    "        model = lambda x, memory, is_training: Hopfield(beta, sim=sim, sep=jax.nn.softmax, self_retrieval=self_retrieval)(x, memory, is_training)\n",
    "    \n",
    "    wandb.config = {\n",
    "        \"batch_size\" : batch_size,\n",
    "        \"epochs\" : epochs,\n",
    "        \"beta\" : beta,\n",
    "        \"encoder_only\" : encoder_only,\n",
    "        \"task_num\" : task_num,\n",
    "        \"method_num\" : method_num,\n",
    "        \"save_as\" : save_as,\n",
    "        \"sweeps\" : sweeps\n",
    "    }\n",
    "    \n",
    "    train_loader_fn = train_loader\n",
    "    train_loader = train_loader(batch_size)\n",
    "    val_loader = val_loader(batch_size)\n",
    "    test_loaders = {k : v(batch_size) for k, v in test_loaders.items()}\n",
    "        \n",
    "    forward = hk.without_apply_rng(hk.transform_with_state(model))\n",
    "    sample_input = jnp.ones([batch_size, 100, 100, 3])\n",
    "    sample_labels = jnp.ones([batch_size, 5])\n",
    "    rng_key = jax.random.PRNGKey(42)\n",
    "    params, state = forward.init(rng_key, sample_input, None, True)\n",
    "    \n",
    "    model2 = lambda x, memory, is_training: Hopfield(beta, sim=sim, sep=jax.nn.softmax, self_retrieval=True)(x, memory, is_training)\n",
    "    forwardl = hk.without_apply_rng(hk.transform_with_state(model2))\n",
    "    \n",
    "    optimizer = optax.adam(1e-4)\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    def prep_data(data, labels):\n",
    "        data, labels = jnp.asarray(data), jnp.asarray(labels)\n",
    "        data = jnp.transpose(data, (0, 2, 3, 1))\n",
    "        return data, labels\n",
    "    \n",
    "    @partial(jax.jit)\n",
    "    def task1_eval(params, state, data, labels, memory):\n",
    "        logits, state = forward.apply(params, state, data, memory, is_training=False) \n",
    "        #print(len(logits), logits[1], \"bisk\")\n",
    "        loss = optax.softmax_cross_entropy(logits[0], labels)\n",
    "        return loss.mean(), (logits, state)\n",
    "    \n",
    "    \n",
    "    def task1_test(params, state, data, labels, memory):\n",
    "        logits, state = forwardl.apply(params, state, data, memory, is_training=False) \n",
    "        print(len(logits), logits[1], \"bisk\")\n",
    "        loss = optax.softmax_cross_entropy(logits[0], labels)\n",
    "        return loss.mean(), (logits, state)\n",
    "    \n",
    "    def task1_loss(params, state, data, labels, memory):\n",
    "        logits, state = forward.apply(params, state, data, memory, is_training=True)\n",
    "        loss = optax.softmax_cross_entropy(logits[0], labels)\n",
    "        return loss.mean(), (logits, state)\n",
    "    \n",
    "    @partial(jax.jit)\n",
    "    def task1_update(params, state, opt_state, data, labels, memory):\n",
    "        grad_fn = jax.value_and_grad(task1_loss, has_aux=True)\n",
    "        ((loss, (logits, state)), grads) = grad_fn(params, state, data, labels, memory)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        return params, state, opt_state, loss, logits\n",
    "        \n",
    "    # compile jitted functions\n",
    "    task1_eval(params, state, sample_input, sample_labels, None)\n",
    "    task1_update(params, state, opt_state, sample_input, sample_labels, None)\n",
    "        \n",
    "    def train_and_val(params, state, opt_state):\n",
    "        for epoch in range(epochs):\n",
    "            t_loss, t_acc = [], []\n",
    "            v_loss, v_acc = [], []\n",
    "            \n",
    "            for data, labels in train_loader:\n",
    "                if task_num == 1:\n",
    "                    data, labels = prep_data(data, labels)\n",
    "                    res = task1_update(params, state, opt_state, data, labels, None)\n",
    "                    (params, state, opt_state, loss, (logits, _)) = res\n",
    "                else: \n",
    "                    pass\n",
    "                t_loss.append(loss)\n",
    "                t_acc.append(get_acc(logits, labels))\n",
    "            wandb.log({\"train_loss\" : float(jnp.array(t_loss).mean()), \"epoch\" : epoch})\n",
    "            wandb.log({\"train_accuracy\" : float(jnp.array(t_acc).mean()), \"epoch\" : epoch})\n",
    "            \n",
    "            for data, labels in val_loader:\n",
    "                if task_num == 1:\n",
    "                    data, labels = prep_data(data, labels)\n",
    "                    loss, ((logits, _), _) = task1_eval(params, state, data, labels, None)\n",
    "                else:\n",
    "                    pass\n",
    "                v_loss.append(loss)\n",
    "                v_acc.append(get_acc(logits, labels))\n",
    "            wandb.log({\"val_loss\" : float(jnp.array(v_loss).mean()), \"epoch\" : epoch})\n",
    "            wandb.log({\"val_accuracy\" : float(jnp.array(v_acc).mean()), \"epoch\" : epoch})\n",
    "            print(f\"Finished epoch {epoch}\")\n",
    "            \n",
    "        if save_as:\n",
    "            with open(save_as, 'wb') as f:\n",
    "                jnp.save(f, (params, state), allow_pickle=True)\n",
    "            \n",
    "        return params, state\n",
    "            \n",
    "    def test(params, state):\n",
    "        if not encoder_only:\n",
    "            model = lambda x, is_training: Hopfield(beta, sim=sim, sep=jax.nn.softmax, self_retrieval=True)(x, is_training)\n",
    "        if pretrained_encoder:\n",
    "            pass\n",
    "        forwardl = hk.without_apply_rng(hk.transform_with_state(model))\n",
    "        \n",
    "        mem_count = [50*i for i in range(1,9)]\n",
    "        memories = [prep_data(*next(iter(train_loader_fn(i)))) for i in mem_count]\n",
    "        results_dicts = {}\n",
    "        \n",
    "        # compiled jitted functions\n",
    "        task1_test(params, state, sample_input, sample_labels, None)\n",
    "        res = {}\n",
    "         \n",
    "        for k, v in test_loaders.items():\n",
    "            acc_without_mem, acc_with_mem = [], []\n",
    "            maps_without_mem, maps_with_mem = None, None\n",
    "            n_labels=None\n",
    "            for data, labels in v:\n",
    "                data, labels = prep_data(data, labels)\n",
    "                \n",
    "                if task_num == 1:\n",
    "                    _, ((logits, attn_map), _) = task1_test(params, state, data, labels, None)\n",
    "                else:\n",
    "                    pass\n",
    "                acc_without_mem.append(get_acc(logits, labels))\n",
    "                if maps_without_mem == None:\n",
    "                    n_labels = labels\n",
    "                maps_without_mem = attn_map if maps_without_mem == None else maps_without_mem\n",
    "                \n",
    "                \n",
    "                if task_num == 1:\n",
    "                    if not encoder_only:\n",
    "                        accs, all_maps = [], []\n",
    "                        for t_data, t_labels in memories: \n",
    "                            _, ((logits, attn_map), _) = task1_test(params, state, data, labels, t_data)\n",
    "                            accs.append(get_acc(logits, labels))\n",
    "                            print(\"orggg\", attn_map.shape)\n",
    "                            all_maps.append((attn_map, t_labels, labels))\n",
    "                        acc_with_mem.append(accs)\n",
    "                else:\n",
    "                    pass\n",
    "                acc_with_mem.append(accs)\n",
    "                maps_with_mem = all_maps if maps_with_mem == None else maps_with_mem\n",
    "                print(\"with mem\", [maps_with_mem[i][0].shape for i in range(len(maps_with_mem))])\n",
    "\n",
    "            wandb.log({f\"{k}_test_accuracy_no_memory\" : float(jnp.array(acc_without_mem).mean())})\n",
    "            acc_with_mem = jnp.array(acc_with_mem).mean(axis=0).tolist()\n",
    "            res[k] = [acc_with_mem, maps_with_mem]\n",
    "            \n",
    "            unencoded_labels = jnp.argmax(n_labels, axis=1).tolist()\n",
    "            unencoded_labels = [f\"{unencoded_labels[i]}({i})\" for i in range(len(unencoded_labels))]\n",
    "            print(len(unencoded_labels), unencoded_labels)\n",
    "            plot_without_mem = pd.DataFrame(maps_without_mem, columns=unencoded_labels, index=unencoded_labels)\n",
    "            plots_without_mem = px.imshow(plot_without_mem, labels=dict(x=\"Inputs\", y=\"Inputs\", color=\"Similarity\"))\n",
    "            wandb.log({f\"{k}_attn_maps_no_memory\" : plots_without_mem})\n",
    "        \n",
    "        keys, values = list(res.keys()), list(res.values())\n",
    "        acc_titles = [f\"{i}_test_accuracy_with_memory\" for i in keys]   \n",
    "        map_titles = [f\"{i}_attn_maps_with_memory\" for i in keys]\n",
    "        \n",
    "        for mem in range(len(memories)):\n",
    "            vals = [[], []]\n",
    "            for v in values:\n",
    "                print(v[0], \"fool\")\n",
    "                vals[0].append(v[0][mem])\n",
    "                attn_map, t_labels, labels = v[1][mem]\n",
    "                print(attn_map.shape, jnp.argmax(labels, axis=1).tolist(), jnp.argmax(t_labels, axis=1).tolist(), \"attttn\")\n",
    "                columns = jnp.argmax(t_labels, axis=1).tolist()\n",
    "                rows = jnp.argmax(labels, axis=1).tolist()\n",
    "                attn_map = pd.DataFrame(attn_map.tolist(), columns=[f\"{columns[i]}({i})\" for i in range(len(columns))] \n",
    "                                       )\n",
    "                attn_map.index = [f\"{rows[i]}({i})\" for i in range(len(rows))]\n",
    "                attn_map = px.imshow(attn_map, labels=dict(\n",
    "                    x=\"Memory\",\n",
    "                    y=\"Inputs\", \n",
    "                    color=\"Similarity\", \n",
    "                    title=f\"N = {mem_count[mem]}\"\n",
    "                ))\n",
    "                vals[1].append(attn_map)\n",
    "            \n",
    "            dict1 = {acc_titles[i] : vals[0][i] for i in range(len(keys))}\n",
    "            dict2 = {map_titles[i] : vals[1][i] for i in range(len(keys))}\n",
    "            dict3 = {\"memories\" : mem_count[mem]}\n",
    "            dict1.update(dict2)\n",
    "            dict1.update(dict3)\n",
    "            print(dict1)\n",
    "            \n",
    "            wandb.log(dict1)\n",
    "            \n",
    "    p, s = train_and_val(params, state, opt_state)\n",
    "    test(p, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c79aae-a834-42a1-8432-4a9d08ec4b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export XLA_PYTHON_CLIENT_MEM_FRACTION=0.7\n",
    "\n",
    "train_val_test(\n",
    "    train_loader=unmasked_train_lfw,\n",
    "    val_loader=unmasked_val_lfw,\n",
    "    test_loaders={\n",
    "        \"truly_masked\" : truly_masked, \n",
    "        \"unmasked_test_lfw\" : unmasked_test_lfw\n",
    "    },\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    "    sim=Hopfield.dot_product,\n",
    "    method_num=2,\n",
    "    task_num=1,\n",
    "    beta=0.001,\n",
    "    encoder_only=False,\n",
    "    pretrained_encoder=False,\n",
    "    save_as=False,\n",
    "    sweeps=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab8b8d-dbb9-4d22-8601-7ca28385649a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beta_sweep():\n",
    "    with wandb.init() as _:\n",
    "        config = wandb.config\n",
    "        !export XLA_PYTHON_CLIENT_MEM_FRACTION=0.7\n",
    "\n",
    "    train_val_test(\n",
    "        train_loader=unmasked_train_lfw,\n",
    "        val_loader=unmasked_val_lfw,\n",
    "        test_loaders={\n",
    "            \"truly_masked\" : truly_masked, \n",
    "            \"unmasked_test_lfw\" : unmasked_test_lfw\n",
    "        },\n",
    "        batch_size=config[\"batch\"],\n",
    "        epochs=1,\n",
    "        sim=config[\"sim\"],\n",
    "        method_num=config[\"method\"],\n",
    "        task_num=1,\n",
    "        beta=config[\"beta\"],\n",
    "        encoder_only=False,\n",
    "        pretrained_encoder=False,\n",
    "        save_as=False,\n",
    "        sweeps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42541781-f0b4-4f8e-8693-c5e32453b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.dot(jnp.ones((2048, 32)), jnp.ones((2048, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d23e1-b499-4357-bf34-955b04e4ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=jnp.ones((100,1))\n",
    "jax.lax.squeeze(s, [1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ac651-8c37-4b3a-85ef-8b7c230dac39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"name\" : \"(32, beta)\",\n",
    "  \"method\" : \"grid\",\n",
    "  \"parameters\" : {\n",
    "    \"beta\"  : {\"values\" : [float(i) for i in \n",
    "                           [32,16,8,4,2,0.1, 0.01, 0.001, \n",
    "                            0.0001]\n",
    "                          ]}, \n",
    "    \"method\" : {\"values\": [1,2]},\n",
    "    \"batch\" : {\"values\":[32, 64, 128]}, \n",
    "    \"sim\" : {\"values\":[\"Hopfield.eucdliean_distance\", \"Hopfield.manhattan_distance\", \"Hopfield.cosine_similarity\", \"Hopfield.dot_product\"]}\n",
    "  }}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"final_hopfield_masked\")\n",
    "wandb.agent(sweep_id, function=beta_sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca89aa53-a487-40fe-bbeb-6296ae77006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucdliean_distance(K, q):\n",
    "        return -jnp.sum(jnp.square(q - K), axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def manhattan_distance(K, q):\n",
    "        return -jnp.sum(jnp.abs(q - K), axis=1)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_similarity(K, q):\n",
    "        return (K @ q) / (torch.norm(K) * torch.norm(q))\n",
    "    \n",
    "    @staticmethod\n",
    "    def dot_product(K, q):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8c86b-aa02-4e38-bdd6-c18390963edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0eca6-0759-4f20-95e1-e7af59c9f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9de716-681a-4d65-8348-27f5e572ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(\"cuda\")\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        labels = labels.to(\"cuda\")\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cde428-c1ca-4361-a8c5-9541eb9dff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t=  lambda x: np.random.choice(3,1)\n",
    "t(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a002f-b1c3-44ac-b94e-e3b23b5b2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack([ t(1) for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78792b8-8a6c-48f3-81b5-dc4a1b0cf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from data import UnmaskedFaces \n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "from pl_bolts.models.self_supervised.simclr.transforms import (\n",
    "    SimCLRTrainDataTransform,  SimCLREvalDataTransform\n",
    ")\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger(name='SimCLR_32', project='associative-vision-models')\n",
    "\n",
    "\n",
    "unmasked_train = UnmaskedFaces(\"train\", SimCLRTrainDataTransform)\n",
    "unmasked_val = UnmaskedFaces(\"val\", SimCLREvalDataTransform)\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1, logger=wandb_logger, gpus=1, default_root_dir=\"simclr\")\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d83cf-3730-4e72-9b90-37a8fe091255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6abbbc-575e-44b9-b275-8270ba023f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.models.resnet50_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08a623-d37c-46ab-87f5-316554e906f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn.functional as F\n",
    "encoder = resnet50()\n",
    "encoder.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a99ea3-f07b-46ce-a4d0-83330a443b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(10, 1)\n",
    "        print(list(self.parameters()))\n",
    "        self.parameters = self.exclude_from_wt_decay(self.named_parameters(),1)\n",
    "        print(list(self.parameters()))\n",
    "        \n",
    "    def exclude_from_wt_decay(self, named_params, weight_decay, skip_list=['bias', 'bn']):\n",
    "        params = []\n",
    "        excluded_params = []\n",
    "\n",
    "        for name, param in named_params:\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            elif any(layer_name in name for layer_name in skip_list):\n",
    "                excluded_params.append(param)\n",
    "            else:\n",
    "                params.append(param)\n",
    "\n",
    "        return [\n",
    "            {'params': params, 'weight_decay': weight_decay},\n",
    "            {'params': excluded_params, 'weight_decay': 0.}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df8f9aa-0920-4490-8ab0-89c3326a4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms as T\n",
    "from pydash import flatten_deep as flatten\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "\n",
    "class GenericDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data, \n",
    "                 labels, \n",
    "                 transforms, \n",
    "                 train_split, \n",
    "                 val_split, \n",
    "                 test_split):\n",
    "        \n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms \n",
    "        \n",
    "        self.train_split = train_split\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "        \n",
    "        self.setup()\n",
    "    \n",
    "    def setup(self):\n",
    "        for i in self.train_split:\n",
    "            self.data[i] = self.transforms[0](self.data[i])\n",
    "        \n",
    "        for i in self.val_split:\n",
    "            if len(self.transforms) >= 2:\n",
    "                t = self.transforms[1]\n",
    "            else: t = self.transforms[-1]\n",
    "            self.data[i] = t(self.data[i])\n",
    "            \n",
    "        for i in self.test_split:\n",
    "            if len(self.transforms) >= 3:\n",
    "                t = self.transforms[2]\n",
    "            else: t = self.transforms[-1]\n",
    "            self.data[i] = t(self.data[i])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class UnmaskedFaces():\n",
    "    def __init__(self, transforms, splits=[0.8, 0.1]):\n",
    "        super().__init__()\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        self.splits = splits\n",
    "        self.transforms = [T.Compose([Image.open, T.ToTensor()]) for t in transforms]\n",
    "        self.label_mapping = {i[1] : i[0] for i in enumerate(os.listdir(\"LFW\"))}\n",
    "        \n",
    "    @staticmethod\n",
    "    def mask_lower_half_of_image(img, value, amount=0.5):\n",
    "        nth_pixel = img[0].shape[0]\n",
    "        half = int(nth_pixel * (1 - amount))\n",
    "        minus_half = nth_pixel - half\n",
    "\n",
    "        if value == 0:\n",
    "            random = torch.rand(3,1)\n",
    "            random=random.unsqueeze(1).repeat(1, half, nth_pixel)\n",
    "            img[:, minus_half:, :]=random\n",
    "            return img\n",
    "        elif value == 1:\n",
    "            random = torch.rand((3, half, nth_pixel))\n",
    "            img[:, minus_half:, :]=random\n",
    "            return img\n",
    "        elif value == 2:\n",
    "            ones = torch.ones(3, half, nth_pixel)\n",
    "            zeros = torch.zeros(3, minus_half, nth_pixel)\n",
    "            mask = torch.concat((ones, zeros), 1) == 0 \n",
    "            mask = torch.reshape(mask, (3, nth_pixel, nth_pixel))\n",
    "            return img.masked_fill(mask, 0)\n",
    "        \n",
    "    @staticmethod\n",
    "    def random_masking_transform():\n",
    "        mask_fn = lambda x: mask_lower_half_of_image(x, random.choice(2,1))\n",
    "        return T.Lambda(mask_fn)\n",
    "\n",
    "    def get_name(self, path):\n",
    "        no_digits = lambda x: not any([i.isdigit() for i in x])\n",
    "        file = path.split(\"/\")[2].split(\"_\")\n",
    "        return \"_\".join(list(filter(no_digits, file)))\n",
    "    \n",
    "    def read_LFW(self):\n",
    "        raw_lfw = [glob.glob(f\"LFW/{person}/*.jpg\") for person in os.listdir(\"LFW\")]\n",
    "        return raw_lfw\n",
    "    \n",
    "    def preprocess(self, sample_list): \n",
    "        images, labels = sample_list, [self.get_name(i) for i in sample_list]\n",
    "        labels = torch.tensor([self.label_mapping[i] for i in labels])\n",
    "        return images, F.one_hot(labels, len(os.listdir(\"LFW\")))\n",
    "    \n",
    "    def generate_dataloader(self):\n",
    "        data = flatten(self.read_LFW())\n",
    "        \n",
    "        indices = np.array(list(range(len(data))))\n",
    "        np.random.permutation(indices)\n",
    "        data_splits = [int(len(indices) * i) for i in self.splits]\n",
    "        \n",
    "        train_split = indices[:data_splits[0]]\n",
    "        val_split = indices[data_splits[0]:data_splits[0]+data_splits[1]]\n",
    "        test_split = indices[data_splits[0]+data_splits[1]:]\n",
    "        \n",
    "        dataset = GenericDataset(*self.preprocess(data), \n",
    "                                 self.transforms,\n",
    "                                 train_split,\n",
    "                                 val_split,\n",
    "                                 test_split)\n",
    "        \n",
    "        return lambda b, m: DataLoader(\n",
    "            dataset, \n",
    "            batch_size=b, \n",
    "            sampler=SubsetRandomSampler(\n",
    "                train_split if m == \"train\" else\n",
    "                val_split if m == \"val\" else\n",
    "                test_split)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1c9a3c-00e2-48b5-af6f-4e10495e1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = UnmaskedFaces([lambda x: x]).generate_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aac1c15-30b4-4585-b821-8579e4c94641",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ulimit -n 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac324e01-7080-4d46-aae2-853e9dc34cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7faaaf6a1610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(64, \"train\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
